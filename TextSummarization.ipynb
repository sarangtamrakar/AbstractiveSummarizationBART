{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextSummarization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lczAj8oBvC7O","executionInfo":{"status":"ok","timestamp":1626414924102,"user_tz":-330,"elapsed":476,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"72f1f83f-22d3-443a-9898-e7669d253f7c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6xBuZRJWDyB","executionInfo":{"status":"ok","timestamp":1626415560166,"user_tz":-330,"elapsed":679,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"d3ddf288-e6aa-4dc0-d7c6-188d6a4bb14d"},"source":["%cd /content/drive/MyDrive/Transformers/Summarization/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Transformers/Summarization\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1WcKIOhbWsQ","executionInfo":{"status":"ok","timestamp":1626410584221,"user_tz":-330,"elapsed":6657,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"e60affaa-860f-4e7e-c9f7-b4d6173ce74d"},"source":["!pip install transformers\n","import transformers\n","import pandas as pd\n","import re\n","import torch\n","torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WT_2bYxPApcg","executionInfo":{"status":"ok","timestamp":1626404719451,"user_tz":-330,"elapsed":23,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"eb69b467-1308-4311-8286-8e9db3fba6a6"},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["crypto_news_parsed_2013-2017_train.csv\tOutputDir\n","Logs\t\t\t\t\tTextSummarization.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i9bdXo6xbW2F","executionInfo":{"status":"ok","timestamp":1626404722567,"user_tz":-330,"elapsed":3128,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["trainData = pd.read_csv(\"crypto_news_parsed_2013-2017_train.csv\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPh079PubW-Y","executionInfo":{"status":"ok","timestamp":1626404722574,"user_tz":-330,"elapsed":43,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["trainData = trainData[['text','title']]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"czw5xG5CvzVt","executionInfo":{"status":"ok","timestamp":1626404722574,"user_tz":-330,"elapsed":40,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":[""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0SmJASObXFO","executionInfo":{"status":"ok","timestamp":1626404722575,"user_tz":-330,"elapsed":39,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"c99d268a-21e1-4991-82ff-20e02106a8ad"},"source":["# check NaN\n","print(\"TrainData\",trainData.isna().sum(),sep=\"\\n\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["TrainData\n","text     3\n","title    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f5lqmu_OdumT","executionInfo":{"status":"ok","timestamp":1626404722576,"user_tz":-330,"elapsed":34,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["# we will drop that rows\n","trainData.dropna(axis=0,how='any',inplace=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBZHS3sheC-X","executionInfo":{"status":"ok","timestamp":1626404722576,"user_tz":-330,"elapsed":32,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"7def716c-4d05-4fd8-f5cc-667f54123934"},"source":["# check NaN\n","print(\"TrainData\",trainData.isna().sum(),sep=\"\\n\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["TrainData\n","text     0\n","title    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiirlPwzeGhU","executionInfo":{"status":"ok","timestamp":1626404722577,"user_tz":-330,"elapsed":25,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"39bef25b-76f2-440a-8357-78de3cbe1761"},"source":["print(trainData.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(28066, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D_ubgPZSayX3","executionInfo":{"status":"ok","timestamp":1626404722577,"user_tz":-330,"elapsed":20,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["train = trainData[:5000]\n","test = trainData[5000:6000]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHE3rP7zbYxo","executionInfo":{"status":"ok","timestamp":1626404722578,"user_tz":-330,"elapsed":20,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["test.reset_index(drop=True,inplace=True)\n","train.reset_index(drop=True,inplace=True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwuQnoqHeGxX","executionInfo":{"status":"ok","timestamp":1626404722578,"user_tz":-330,"elapsed":20,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["def CleanData(text):\n","  new_text = \" \".join(text.split(\". \"))\n","  return new_text"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVg6-V5yeG5M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626404722579,"user_tz":-330,"elapsed":20,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"346892c1-88c6-47ce-edf5-2cf408a03609"},"source":["train['text'] = train['text'].apply(lambda text : CleanData(text=text))\n","test['text'] = test['text'].apply(lambda text : CleanData(text=text))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rrNvCc6XeKJf","executionInfo":{"status":"ok","timestamp":1626404722580,"user_tz":-330,"elapsed":16,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":[""],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4P-hMgeeK1h"},"source":["**DATA PREPARATION**"]},{"cell_type":"code","metadata":{"id":"KapA8J5meG_n","executionInfo":{"status":"ok","timestamp":1626404723217,"user_tz":-330,"elapsed":652,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["# start Model\n","from transformers import BartForConditionalGeneration,BartTokenizer\n","\n","tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLqci0qnkzoQ","executionInfo":{"status":"ok","timestamp":1626404723220,"user_tz":-330,"elapsed":13,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["def PrepareData(text_lis,label_text):\n","  input_ids = []\n","  attention_mask = []\n","  labels = []\n","\n","\n","  for text,ltext in zip(text_lis,label_text):\n","    encoding = tokenizer.encode_plus(text, \n","                          add_special_tokens=True,padding=\"max_length\", \n","                          truncation=True,max_length=512, \n","                          is_split_into_words=False,\n","                          return_tensors=\"pt\",\n","                          return_attention_mask=True)\n","    with tokenizer.as_target_tokenizer():\n","      lencoding = tokenizer.encode_plus(ltext, \n","                          add_special_tokens=True,padding=\"max_length\", \n","                          truncation=True,max_length=128, \n","                          is_split_into_words=False,\n","                          return_tensors=\"pt\",\n","                          return_attention_mask=True)\n","      \n","    input_ids.append(encoding['input_ids'])\n","    attention_mask.append(encoding['attention_mask'])\n","    labels.append(lencoding['input_ids'])\n","\n","\n","  input_ids = torch.cat(input_ids,dim=0)\n","  attention_mask = torch.cat(attention_mask,dim=0)\n","  labels = torch.cat(labels,dim=0)\n","\n","  TrainDict = {\n","      \"input_ids\":input_ids,\n","      \"attention_mask\":attention_mask,\n","      \"labels\":labels\n","      }\n","  return TrainDict"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0h7IN8voUf4","executionInfo":{"status":"ok","timestamp":1626404761325,"user_tz":-330,"elapsed":38115,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["TrainDict = PrepareData(train['text'],train['title'])\n","TestDict = PrepareData(test['text'],test['title'])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZBcnegFk0Ch","executionInfo":{"status":"ok","timestamp":1626404761326,"user_tz":-330,"elapsed":45,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["class CustomDataSet(torch.utils.data.Dataset):\n","  def __init__(self,TrainDict):\n","    self.TrainDict = TrainDict\n","\n","  def __len__(self):\n","    return len(self.TrainDict['input_ids'])\n","\n","  def __getitem__(self,index):\n","    self.input_ids = self.TrainDict['input_ids'][index]\n","    self.attention_mask = self.TrainDict['attention_mask'][index]\n","    self.labels = self.TrainDict['labels'][index]\n","\n","    dic = {\n","        \"input_ids\": self.input_ids,\n","        \"attention_mask\": self.attention_mask,\n","        \"labels\": self.labels\n","    }\n","\n","    return dic"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"IcblwDkVpr1G","executionInfo":{"status":"ok","timestamp":1626404761327,"user_tz":-330,"elapsed":38,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["TrainDataSet = CustomDataSet(TrainDict)\n","TestDataSet = CustomDataSet(TestDict)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdkp6skK9LnQ","executionInfo":{"status":"ok","timestamp":1626404761327,"user_tz":-330,"elapsed":36,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["from torch.utils.data import DataLoader"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sugd-E269Lxm","executionInfo":{"status":"ok","timestamp":1626404761328,"user_tz":-330,"elapsed":34,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["trainLoader = DataLoader(TrainDataSet)\n","testLoader = DataLoader(TestDataSet)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nSSxCpvseDfY"},"source":["**MODEL BUILDING**"]},{"cell_type":"code","metadata":{"id":"9hkdSRBQk0RE","executionInfo":{"status":"ok","timestamp":1626404763307,"user_tz":-330,"elapsed":2012,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["from transformers import BartForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sRhce5_k0by","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626404772653,"user_tz":-330,"elapsed":9354,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"0c157689-4804-41ac-c59e-03388ad2c8c7"},"source":["Model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\").to(torch_device)\n","Model.train()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 1024, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"rzkHFWuPk0oF","executionInfo":{"status":"ok","timestamp":1626404772654,"user_tz":-330,"elapsed":30,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["args = Seq2SeqTrainingArguments(output_dir = \"OutputDir/\",\n","                                num_train_epochs=2.0,\n","                                do_train=True, do_eval=True,\n","                                evaluation_strategy = 'epoch', \n","                                per_device_train_batch_size=1,\n","                                per_device_eval_batch_size=1,\n","                                learning_rate=5e-05, \n","                                logging_dir=\"Logs/\",\n","                                logging_strategy='epoch',\n","                                save_strategy='epoch'\n","                    )"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"clBs1s8-w0h2","executionInfo":{"status":"ok","timestamp":1626404772655,"user_tz":-330,"elapsed":26,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"_A42-DHPdtIT","executionInfo":{"status":"ok","timestamp":1626404772657,"user_tz":-330,"elapsed":25,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["trainer = Seq2SeqTrainer(\n","    Model,\n","    args,\n","    train_dataset=TrainDataSet,\n","    eval_dataset=TestDataSet)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"AIXMr2px28ld","executionInfo":{"status":"ok","timestamp":1626414941377,"user_tz":-330,"elapsed":548,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["# function ClickConnect(){\n","# console.log(\"Working\"); \n","# document.querySelector(\"colab-toolbar-button#connect\").click() \n","# }\n","# setInterval(ClickConnect,60000)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzpGVkiUyl_v","executionInfo":{"status":"ok","timestamp":1626404783407,"user_tz":-330,"elapsed":536,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["torch.cuda.empty_cache()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"l0u4wJTAxP8S","executionInfo":{"status":"ok","timestamp":1626409672314,"user_tz":-330,"elapsed":4887188,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"00e3f131-2ea0-41b5-dd81-9906e485b222"},"source":["trainer.train()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 5000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 10000\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 1:21:24, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.433400</td>\n","      <td>0.271747</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.198500</td>\n","      <td>0.241063</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 1\n","Saving model checkpoint to OutputDir/checkpoint-5000\n","Configuration saved in OutputDir/checkpoint-5000/config.json\n","Model weights saved in OutputDir/checkpoint-5000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 1\n","Saving model checkpoint to OutputDir/checkpoint-10000\n","Configuration saved in OutputDir/checkpoint-10000/config.json\n","Model weights saved in OutputDir/checkpoint-10000/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=10000, training_loss=0.3159576171875, metrics={'train_runtime': 4885.3265, 'train_samples_per_second': 2.047, 'train_steps_per_second': 2.047, 'total_flos': 1.248127352832e+16, 'train_loss': 0.3159576171875, 'epoch': 2.0})"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"PqQrSTh1d3Zx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626409675499,"user_tz":-330,"elapsed":1413,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"62a979ea-9124-4849-d8d8-90f7a3c1e1d4"},"source":["tokenizer.save_pretrained(\"TokenizerDir/\")"],"execution_count":30,"outputs":[{"output_type":"stream","text":["tokenizer config file saved in TokenizerDir/tokenizer_config.json\n","Special tokens file saved in TokenizerDir/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["('TokenizerDir/tokenizer_config.json',\n"," 'TokenizerDir/special_tokens_map.json',\n"," 'TokenizerDir/vocab.json',\n"," 'TokenizerDir/merges.txt',\n"," 'TokenizerDir/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bh9YaMY-SZy5","executionInfo":{"status":"ok","timestamp":1626414958483,"user_tz":-330,"elapsed":466,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"3f0b6725-7718-4e64-b3e7-a1d55fc74ded"},"source":["!ls"],"execution_count":7,"outputs":[{"output_type":"stream","text":["OutputDir  Quantized.pt  TextSummarization.ipynb  TokenizerDir\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_8HAOrcFd4LN"},"source":["**PREDICTION PIPELINE**"]},{"cell_type":"code","metadata":{"id":"7mbmj983R8g9","executionInfo":{"status":"ok","timestamp":1626415658334,"user_tz":-330,"elapsed":80032,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","from transformers import BartForConditionalGeneration,BartTokenizer\n","Model = BartForConditionalGeneration.from_pretrained(\"OutputDir/checkpoint-10000\").to(device)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgJl_ZPWmkmT","executionInfo":{"status":"ok","timestamp":1626415658335,"user_tz":-330,"elapsed":37,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["from transformers import BartTokenizer\n","tokenizer = BartTokenizer.from_pretrained(\"TokenizerDir/\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4eIHgvHSp-P","executionInfo":{"status":"ok","timestamp":1626415658336,"user_tz":-330,"elapsed":33,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["text = \"Causal language modeling is the task of predicting the token following a sequence of tokens. In this situation, the model only attends to the left context (tokens on the left of the mask). Such a training is particularly interesting for generation tasks. If you would like to fine-tune a model on a causal language modeling task, you may leverage the run_clm.py script.\"\n","\n","input_ids = []\n","attention_mask = []\n","\n","encoding = tokenizer.encode_plus(text, \n","                          add_special_tokens=True,padding=\"max_length\", \n","                          truncation=True,max_length=512, \n","                          is_split_into_words=False,\n","                          return_tensors=\"pt\",\n","                          return_attention_mask=True)\n","\n","input_ids.append(encoding['input_ids'])\n","attention_mask.append(encoding['attention_mask'])\n","\n","\n","input_ids = torch.cat(input_ids,dim=0)\n","attention_mask = torch.cat(attention_mask,dim=0)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"72yHLCZdev-Y","executionInfo":{"status":"ok","timestamp":1626415851298,"user_tz":-330,"elapsed":449,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["data = {\n","    \"input_ids\":input_ids.to(\"cpu\"),\n","    \"attention_mask\":attention_mask.to(\"cpu\")\n","}"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"fff_twEiX-az","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626415699014,"user_tz":-330,"elapsed":6,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"76faf108-9489-42f9-e7af-dbe365d56f45"},"source":["res = Model.generate(**data,\n","                max_length=512, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True)\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0LrqGluoT6Q","executionInfo":{"status":"ok","timestamp":1626415703664,"user_tz":-330,"elapsed":490,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"4c0d005c-1da6-4d67-f17c-33d03534b3cc"},"source":["res"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    2,     0, 38593, 25016, 22205,  7192,  1058,     2]],\n","       device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"KB5vnbwlbK14","executionInfo":{"status":"ok","timestamp":1626415714420,"user_tz":-330,"elapsed":7723,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["preds = [tokenizer.decode(res[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)]\n","# target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in labels]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ntRGXdbde_D3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626415714421,"user_tz":-330,"elapsed":14,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"f82013cd-f9d5-4352-862d-7aacae4109e9"},"source":["print(preds,sep=\"\\n\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['Causal Language Model training']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FzzeQhHnZw-w","executionInfo":{"status":"ok","timestamp":1626411109227,"user_tz":-330,"elapsed":541,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["# print(preds,target,sep=\"\\n\")"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWQiFeoQimpS","executionInfo":{"status":"ok","timestamp":1626415720441,"user_tz":-330,"elapsed":553,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["context = [tokenizer.decode(i,skip_special_tokens=True, clean_up_tokenization_spaces=True) for i in input_ids]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFv7oTCXjBJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626415722083,"user_tz":-330,"elapsed":793,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"3173a09f-68f3-4253-e622-daff43b4fc19"},"source":["print(context,preds,sep=\"\\n\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['Causal language modeling is the task of predicting the token following a sequence of tokens. In this situation, the model only attends to the left context (tokens on the left of the mask). Such a training is particularly interesting for generation tasks. If you would like to fine-tune a model on a causal language modeling task, you may leverage the run_clm.py script.']\n","['Causal Language Model training']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P9nrCl0kdthF"},"source":["**MODEL DYNAMIC QUANTIZATION**\n"]},{"cell_type":"code","metadata":{"id":"wgjmQIMPMoyP","executionInfo":{"status":"ok","timestamp":1626415942044,"user_tz":-330,"elapsed":30948,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["# ALWAYS QUANTIZED ON THE CPU BACKEND... \n","quantize_model  = torch.quantization.quantize_dynamic(\n","    Model.to(\"cpu\"),  # the original model # \n","    {torch.nn.Linear},  # a set of layers to dynamically quantize\n","    dtype=torch.float16\n","    )"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"StWh5SjeVQq0","executionInfo":{"status":"ok","timestamp":1626417033799,"user_tz":-330,"elapsed":56779,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["# Always Prefered\n","# torch.save(quantize_model,\"QuantizedFloat16.pt\")\n","Quantized =  torch.load(\"QuantizedFloat16.pt\")"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFb200PLYYG8"},"source":["# quantize_model.save_pretrained(\"QuantizedModel/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ARXsK9f3Y4n0"},"source":["# tokenizer.save_pretrained(\"QuantizedModel/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NET2ZvV1Y4yt"},"source":["# tokenizer = BartTokenizer.from_pretrained(\"QuantizedModel/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPbFhhWbSHTv","executionInfo":{"status":"ok","timestamp":1626417156317,"user_tz":-330,"elapsed":6227,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["res = Quantized.generate(**data,\n","                max_length=128, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvcK9qOlrVzU","executionInfo":{"status":"ok","timestamp":1626417159910,"user_tz":-330,"elapsed":456,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["preds = [tokenizer.decode(res[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)]"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8cJnuXVyrnf9","executionInfo":{"status":"ok","timestamp":1626417161400,"user_tz":-330,"elapsed":24,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"76aefdb4-9426-49ef-bc05-08fc9ab1a878"},"source":["preds[0]"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Causal Language Model training'"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"BV7SczZGSHcq","executionInfo":{"status":"ok","timestamp":1626411730625,"user_tz":-330,"elapsed":5,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}}},"source":["%load_ext tensorboard"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJijtYmzSUd0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626411732306,"user_tz":-330,"elapsed":19,"user":{"displayName":"sarang tamrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiygD8soHFHwnL50GjUAlsd7jf8mnM-DDZWG-pqb38=s64","userId":"13053906188370509008"}},"outputId":"da21557d-63f2-475a-81f1-25776cd74b75"},"source":["!ls"],"execution_count":85,"outputs":[{"output_type":"stream","text":["OutputDir  Quantized.pt  TextSummarization.ipynb  TokenizerDir\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YKawE_30SahV"},"source":["%tensorboard --logdir Logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G53t5akWoSxU"},"source":[""],"execution_count":null,"outputs":[]}]}